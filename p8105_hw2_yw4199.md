p8105_hw2_yw4199
================
Yaduo Wang
2023-10-01

# Problem 2

``` r
library(tidyverse)
library(readxl)
```

``` r
trash_data = read_excel("Trash_Collection_uodated.xlsx", sheet = 1, skip = 1)
#specify the sheet in the Excel file and to omit non-data entries
trash_data = janitor::clean_names(trash_data)
#use reasonable variable names

Mr.trash = 
  trash_data |> 
  select(dumpster:homes_powered) |> 
  drop_na(dumpster) |> 
#omit rows that do not include dumpster-specific data
  mutate(homes_powered = weight_tons*500/30)
#Update the data to include a new homes_powered variable based on this calculation.
```

``` r
Pro_data = read_excel("Trash_Collection_uodated.xlsx", sheet = 2, skip = 1)
#specify the sheet in the Excel file and to omit non-data entries
Pro_data = janitor::clean_names(Pro_data)
#use reasonable variable names

Pro.trash = 
  Pro_data |> 
  select(dumpster:homes_powered) |> 
  drop_na(dumpster) |> 
#omit rows that do not include dumpster-specific data
  mutate(homes_powered = weight_tons*500/30)
#Update the data to include a new homes_powered variable based on this calculation.
```

``` r
Gwy_data = read_excel("Trash_Collection_uodated.xlsx", sheet = 4, skip = 1)
#specify the sheet in the Excel file and to omit non-data entries
Gwy_data = janitor::clean_names(Gwy_data)
#use reasonable variable names

Gwy.trash = 
  Gwy_data |> 
  select(dumpster:homes_powered) |> 
  drop_na(dumpster) |> 
#omit rows that do not include dumpster-specific data
  mutate(homes_powered = weight_tons*500/30)
#Update the data to include a new homes_powered variable based on this calculation.
```

Combine all three datasets.

``` r
#add an additional variable to all datasets before combining
Mr.trash = 
  Mr.trash |> 
  mutate(name_sheet = "Mr.Trash Wheel",
         year = as.numeric(year))
Pro.trash = 
  Pro.trash |> 
  mutate(name_sheet = "Professor Trash Wheel",
         year = as.numeric(year)) 
Gwy.trash = 
  Gwy.trash |> 
  mutate(name_sheet = "Gwynnda Trash Wheel",
         year = as.numeric(year)) 

#keep the variable type constant
```

``` r
#combine all three datasets
three_tidy = 
  bind_rows(Mr.trash, Pro.trash, Gwy.trash) |>
  janitor::clean_names()
```

Description of the data

``` r
sum_weight_Professor = filter(three_tidy, name_sheet == "Professor Trash Wheel")
sum_gwy = filter(three_tidy, 
                 month == "July", year == 2021, name_sheet =="Gwynnda Trash Wheel")
```

This new dataset contains 845 rows, and 15 columns. The columns in this
dataset include: dumpster, month, year, date, weight_tons,
volume_cubic_yards, plastic_bottles, polystyrene, cigarette_butts,
glass_bottles, plastic_bags, wrappers, sports_balls, homes_powered,
name_sheet. The total weight of trash collected by Professor Trash Wheel
is 216.26. The total number of cigarette butts collected by Gwynnda in
July of 2021 is 1.63^{4}.

# Problem 3

``` r
#Import and clean the dataset. 
baseline_initial = 
  read_csv(file = "MCI_baseline.csv", skip = 1)|>
  janitor::clean_names()

#tidy the dataset
baseline_data = 
  baseline_initial |> 
  mutate(sex = 
      case_match(
        sex, 
        1 ~ "male", 
        0 ~ "female"),
    sex = as.factor(sex)) |> 
   mutate(apoe4 = 
      case_match(
        apoe4, 
        1 ~ "APOE4 carrier", 
        0 ~ "APOE4 non-carrier"),
    apoe4 = as.factor(apoe4)) |> 
  #appropriate encoded of sex and APOE4 carrier status
  subset(current_age < age_at_onset | age_at_onset == ".") 
  #remove any participants who do not meet the stated inclusion criteria

baseline_data_onset = 
  baseline_data |> 
  filter(age_at_onset != ".") 
```

``` r
APOE4_carriers = 
  baseline_data |> 
  filter(apoe4 == "APOE4 carrier") 
```

First, we import data in the form of csv file, and we dropped the first
row. We use reasonable variable names. We apply the appropriate encoded
for sex and APOE4 carrier status variables. Then, we remove any
participants whose current_age is larger than age_at_onset. There are483
participants recruited, and 479 participants who meet the stated
inclusion criteria. There are 93 participants develop MCI. The average
baseline age is 65.0286013. The proportion of women in the study who are
APOE4 carriers is 30.0626305%.

``` r
amyloid_data = 
  read_csv(file = "mci_amyloid.csv", skip = 1) |> 
  janitor::clean_names() |> 
  rename("id" = "study_id") |> 
  filter(baseline!="Na") |> 
  pivot_longer(
    baseline:time_8,
    names_to = "period", 
    values_to = "values") 
```

We read in the dataset and skip the first line. We rename the student id
and filter out the unnecessary data. Then, we use the pivot_longer the
rearrange the dataset.

``` r
unique_baseline = anti_join(baseline_data, amyloid_data)
unique_amyloid = anti_join(amyloid_data, baseline_data)
```

``` r
#Combine the demographic and biomarker datasets so that only participants who appear in both datasets are retained.
combined_data <- inner_join(baseline_data, amyloid_data, by = "id")
# export the result as a CSV to my data directory
write.csv(combined_data, "combined_dataset.csv", row.names = FALSE)
```

9 participants appear in only the baseline and 15 participants only
appear in amyloid datasets. There are total 470 participants.

(# Problem 1

We clean the 538 `pols` data, which provides information on the number
of national politicians who are democratic or republican at any given
time. There are some values for which `prez_gop` is `2` – these are
months in which Ford became President following Nixon’s resignation. In
the new `president` variable created as part of our data cleaning, we
code these as `gop` (same as values when `prez_gop` is `1`).

``` r
month_df = 
  tibble(
    month_num = 1:12,
    month_abb = month.abb,
    month = month.name
  )

pols = 
  read_csv("pols-month.csv") |>
  separate(mon, into = c("year", "month_num", "day"), convert = TRUE) |>
  mutate(
    president = recode(prez_gop, "0" = "dem", "1" = "gop", "2" = "gop")) |>
  left_join(x = _, y = month_df) |> 
  select(year, month, everything(), -day, -starts_with("prez")) 
```

We also clean the 538 `snp` data, which contains information related to
Standard & Poor’s stock market index.

``` r
snp = 
  read_csv(
    "snp.csv",
    col_types = cols(date = col_date(format = "%m/%d/%y"))) |>
  separate(date, into = c("year", "month_num", "day"), convert = TRUE) |>
  mutate(
    year = if_else(year > 2023, year - 100, year)) |> 
  left_join(x = _, y = month_df) |> 
  select(year, month, close) 
```

Finally, we tidy the `unemployment` data so that it can be merged with
the `pols` and `snp` datasets.

``` r
unemployment = 
  read_csv("unemployment.csv") |>
  rename(year = Year) |>
  pivot_longer(
    Jan:Dec, 
    names_to = "month_abb",
    values_to = "unemployment"
  ) |> 
  left_join(x = _, y = month_df) |> 
  select(year, month, unemployment)
```

Now we merge the three datasets!

``` r
data_538 = 
  left_join(pols, snp) |>
  left_join(x = _, y = unemployment)
```

Notice that there are some `NA` values in the `close` and `unemployment`
variables, which indicate that the value of these variables is missing
at those locations.

Let’s talk about the 538 datasets. The `pols` data has 822 observations
and 11 variables and tells us about the party affiliation distribution
(democrat or republican) for governors and senators for a given year
from years 1947 to 2015. It also tells us whether the sitting president
was a democrat or republican. The `snp` data has 787 observations and 3
variables, ranging from years 1950 to 2015. The `unemployment` data has
816 observations and 3 variables ranging from years 1948 to 2015. In
Januarys in or after 1975 in which a democrat was president, the
**average unemployment rate was 6.57**. The average unemployment rate
over the same time period in which a republican was president was 6.47.)
